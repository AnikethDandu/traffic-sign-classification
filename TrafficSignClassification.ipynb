{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrafficSignClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMclSCv8A9oIwjsrB+k8IiH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnikethDandu/traffic-sign-classification/blob/main/TrafficSignClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPE0QpmtL9y2"
      },
      "source": [
        "# **Traffic Sign Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDRPiq7M-y2"
      },
      "source": [
        "## **Import Libraries**\n",
        "Python standard libraries. If there are problems with torch, run the following command\n",
        "```\n",
        "# !pip install torch\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ5biOPK3mdf"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCycgL3iNHHZ"
      },
      "source": [
        "## **Main Script Variable Initialization**\n",
        "This cell initializes variables for the main script. It includes hyperparameters for the network, a standard image size, the datatsets and dataloaders, and the path to the training data folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCnIB_Hm47cd"
      },
      "source": [
        "# Network hyperparameters\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Tuple for desired standard image size after resizing\n",
        "image_size = (-1, 3, 50, 50)\n",
        "\n",
        "# Variables holding training and evaluation datasets and dataloaders\n",
        "training_dataset = None\n",
        "testing_dataset = None\n",
        "train_dataloader = None\n",
        "test_dataloader = None\n",
        "\n",
        "# Path to folders holding training data sorted by class\n",
        "train_path = 'traffic_sign_images/Train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjJrsqdxNKPH"
      },
      "source": [
        "## **Convolutional Neural Network**\n",
        "A PyTorch CNN class with 4 Convolutional layers and 2 Linear layers. The ReLU and max pooling functions are applied after each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2zvNd8X31UI"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  \"\"\"\n",
        "  Convolution Neural Network class\n",
        "  Extends torch.nn.Module base network initialization\n",
        "  Overrides torch.nn.Module forward method\n",
        "\n",
        "  PUBLIC METHODS:\n",
        "    - forward(self, x)\n",
        "\n",
        "  INSTANCE VARIABLES:\n",
        "    - PADDING_SIZE\n",
        "    - KERNEL_SIZE\n",
        "    - STRIDE\n",
        "    - POOL_SIZE\n",
        "    - conv1\n",
        "    - conv2\n",
        "    - conv3\n",
        "    - conv4\n",
        "    - fc1\n",
        "    - fc2\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Initializes network layers for input image of size 32x32x3\n",
        "\n",
        "    :var PADDING_SIZE: size of padding applied to all sides of input matrix to\n",
        "      preserve input volume\n",
        "    :type: int\n",
        "    :var KERNEL_SIZE: size of feature extraction filter\n",
        "    :type: int\n",
        "    :var STRIDE: pixel translation length during convolution operation\n",
        "    :type: int\n",
        "    :var POOL_SIZE: size of pooled feature map\n",
        "    :type: int\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    self.PADDING_SIZE = 1\n",
        "    self.KERNEL_SIZE = 3\n",
        "    self.STRIDE = 1\n",
        "    self.POOL_SIZE = 2\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, \n",
        "                           kernel_size=self.KERNEL_SIZE, \n",
        "                           stride=self.STRIDE, \n",
        "                           padding=self.PADDING_SIZE)\n",
        "    self.conv2 = nn.Conv2d(32, 64, \n",
        "                           kernel_size=self.KERNEL_SIZE, \n",
        "                           stride=self.STRIDE, \n",
        "                           padding=self.PADDING_SIZE)\n",
        "    self.conv3 = nn.Conv2d(64, 128, \n",
        "                           kernel_size=self.KERNEL_SIZE, \n",
        "                           stride=self.STRIDE, \n",
        "                           padding=self.PADDING_SIZE)\n",
        "    self.conv4 = nn.Conv2d(128, 256, \n",
        "                           kernel_size=self.KERNEL_SIZE, \n",
        "                           stride=self.STRIDE, \n",
        "                           padding=self.PADDING_SIZE)\n",
        "    self.fc1 = nn.Linear(2304, 512)\n",
        "    self.fc2 = nn.Linear(512, 43)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Passes input matrix through network convolutional and linear layers while \n",
        "    applying pooling and ReLU function\n",
        "\n",
        "    :param x: input matrix\n",
        "    :type: torch.tensor\n",
        "    :return: class output matrix\n",
        "    :rtype: torch.tensor\n",
        "    \"\"\"\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), self.POOL_SIZE)\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), self.POOL_SIZE)\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), self.POOL_SIZE)\n",
        "    x = F.max_pool2d(F.relu(self.conv4(x)), self.POOL_SIZE)\n",
        "    x = x.flatten(start_dim=1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8Fq0ceYNOGS"
      },
      "source": [
        "## **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLxUiPzfNi2n"
      },
      "source": [
        "### **Custom Dataset Class**\n",
        "This class was created by subclassing the PyTorch Dataset class to easily read the training and evaluation csv and iterate over the dataset \\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKU0VKEt7laU"
      },
      "source": [
        "class TrafficSignDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Custom Dataset class\n",
        "  Subclasses torch.utils.data.Dataset\n",
        "\n",
        "  DUNDER METHODS:\n",
        "    - __len__(self)\n",
        "    - __getitem__(self, idx)\n",
        "\n",
        "  INSTANCE VARIABLES:\n",
        "    - train\n",
        "    - root_dir\n",
        "    - img_size\n",
        "    - df\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, train, root_dir, img_size):\n",
        "    \"\"\"\n",
        "    Initializes instance variables for given parameters\n",
        "\n",
        "    :param train: whether dataset is a train or evaluation dataset\n",
        "    :type: bool\n",
        "    :param root_dir: root directory of files\n",
        "    :type: str\n",
        "    :param img_size: desired length of one side of resized image\n",
        "    :type: int\n",
        "    :var df: reads and displays csv file as two-axis display\n",
        "    :type: DataFrame\n",
        "    \"\"\"\n",
        "    self.train = train\n",
        "    self.root_dir = root_dir\n",
        "    self.df = pd.read_csv(os.path.join(root_dir, 'Train.csv' if train else 'Test.csv'))\n",
        "    self.img_size = img_size\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    Returns length of csv file corresponding to dataset\n",
        "\n",
        "    :return: length of csv file\n",
        "    :rtype: int\n",
        "    \"\"\"\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Returns image from dataset at specific index along with class label\n",
        "\n",
        "    :param idx: index of desired item to get\n",
        "    :type: int\n",
        "    :return: returns dictionary of image with corresponding label\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "    image = cv2.imread(os.path.join(self.root_dir, self.df.iloc[idx][7]), cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (self.img_size, self.img_size))\n",
        "    label = self.df.iloc[idx][6]\n",
        "    sample = {'image': torch.tensor(image), 'label': self.df.iloc[idx][6]}\n",
        "    return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITUhF2D5NRU-"
      },
      "source": [
        "### **Dataset creation function**\n",
        "This function reassigns global variables to Dataset and DataLoader classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOdO6gNr4m0Z"
      },
      "source": [
        "def create_datasets():\n",
        "  \"\"\"\n",
        "  Reassigns global training variables to corresponding datasets and dataloaders\n",
        "  \"\"\"\n",
        "  global training_dataset\n",
        "  global testing_dataset\n",
        "  global train_dataloader\n",
        "  global test_dataloader\n",
        "\n",
        "  training_dataset = TrafficSignDataset(train=True, root_dir='traffic_sign_images', img_size=50)\n",
        "  testing_dataset = TrafficSignDataset(train=False, root_dir='traffic_sign_images', img_size=50)\n",
        "  \n",
        "  train_dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "  test_dataloader = DataLoader(testing_dataset, batch_size=1, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbWHTZ4gNlN8"
      },
      "source": [
        "## **Model Training and Evaluation**\n",
        "The below functions use the network given in the function parameter and train / evaluate it using the corresponding datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2LBbxIkNtBs"
      },
      "source": [
        "### **Model Training Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCRmtcZj5c3D"
      },
      "source": [
        "def train_model(net):\n",
        "  \"\"\"\n",
        "  The model training function\n",
        "  Prints epoch number and corresponding loss after every iteration\n",
        "\n",
        "  :param net: CNN to be trained\n",
        "  :type net: torch.nn.Module\n",
        "  \"\"\"\n",
        "  for epoch in range(EPOCHS):\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "      batch_imgs, batch_lbls = batch[\"image\"].view(image_size) / 255.0, batch[\"label\"]\n",
        "      batch_labels = [0 for i in range(BATCH_SIZE)]\n",
        "      for label_idx, label in enumerate(batch_lbls):\n",
        "        batch_labels[label_idx] = label.item()\n",
        "        \n",
        "      batch_imgs = batch_imgs\n",
        "      batch_labels = batch_labels\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(batch_imgs.to(device))\n",
        "      loss = criterion(outputs, torch.tensor([label for label in batch_labels], device=device).long())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {loss}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzne8eUYNYfL"
      },
      "source": [
        "### **Model Evaluation Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kn17ASC5yr4"
      },
      "source": [
        "def evaluate_model(net):\n",
        "  \"\"\"\n",
        "  The model evaluation function\n",
        "  Prints accuracy for each class, raw class total correct, and total image accuracy and raw score\n",
        "\n",
        "  :param net: CNN to be trained\n",
        "  :type net: torch.nn.Module\n",
        "  \"\"\"\n",
        "  total_classes = {}\n",
        "  class_correct = {}\n",
        "  total_images = 0\n",
        "  total_correct = 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_dataloader):\n",
        "      test_image, test_label = batch['image'].view(image_size) / 255.0, batch['label'].item()\n",
        "      correct_class = test_label\n",
        "      test_image = test_image.to(device)\n",
        "      predicted_class = torch.argmax(net(test_image)[0])\n",
        "      \n",
        "      total_images += 1\n",
        "      total_classes[predicted_class.item()] = total_classes[predicted_class.item()] + 1 if predicted_class.item() in total_classes else 1\n",
        "      \n",
        "      if predicted_class == correct_class:\n",
        "        total_correct += 1\n",
        "        class_correct[correct_class] = class_correct[correct_class] + 1 if correct_class in class_correct else 1\n",
        "  print([f'Accuracy for {img_class}: {round(100 * class_correct[img_class] / total_classes[img_class], 3)}%' for img_class in class_correct])\n",
        "  print(f'Raw class score: {class_correct}')\n",
        "  print(f'Total images correct: {total_correct}, Total images: {total_images}, Total accuracy: {round(100 * total_correct / total_images, 3)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw0rDAGFN1eb"
      },
      "source": [
        "## **Main Script**\n",
        "The main script uses the GPU if available, creates the datasets, CNN, Adam optimizer, CrossEntropyLoss criterion with class weights, and trains and evaluates the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJkt76LEHJ76"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "# Create both training and evaluation datasets\n",
        "create_datasets()\n",
        "\n",
        "# Calculate total number of images in training dataset\n",
        "total_images = 0\n",
        "class_count = []\n",
        "for folder in os.listdir(train_path):\n",
        "  if folder != '.DS_Store':\n",
        "    image_count = len([img for img in os.listdir(os.path.join(train_path, folder))])\n",
        "    class_count.append(image_count)\n",
        "    total_images += image_count\n",
        "\n",
        "# Calculate the class weights (due to unequal class image sizes)\n",
        "final_weights = torch.Tensor([1 - img_count/total_images for img_count in class_count]).to(device)\n",
        "# Create the CNN on the GPU\n",
        "conv_net = ConvNet().to(device)                        \n",
        "# Initializes optimizer and criterion\n",
        "optimizer = optim.Adam(conv_net.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(weight=final_weights)\n",
        "\n",
        "# Train and evaluate the model\n",
        "train_model(conv_net)\n",
        "evaluate_model(conv_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7glLQXmMN9RO"
      },
      "source": [
        "## **Google Drive Dataset Import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQgAG3K6-u43"
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp -r /content/gdrive/My\\ Drive/ColabNotebooks/Data/ traffic_sign_images.zip\n",
        "!unzip traffic_sign_images.zip/traffic_sign_images.zip\n",
        "!rm -r traffic_sign_images.zip/\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}